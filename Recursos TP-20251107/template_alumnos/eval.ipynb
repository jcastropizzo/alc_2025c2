{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from dataset import cargarDataset\n",
    "from pathlib import Path\n",
    "import time\n",
    "from alc import (svd_reducida, QR_con_GS, transpuesta,\n",
    "QR_con_HH, validate_transferlearning,\n",
    "matriz_confusion, esPseudoInversa,\n",
    "pinvHouseHolder, pinvGramSchmidt, pinvSVD, pinvEcuacionesNormales)"
   ],
   "id": "f5d15eb0bf600167"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data_path = Path(\"./dataset/cats_and_dogs\")\n",
    "X_train, Y_train, X_val, Y_val = cargarDataset(data_path)"
   ],
   "id": "2c08ed21008ba759"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "    #Cholesky\n",
    "    print(\"running cholesky...\")\n",
    "    start_time = time.perf_counter()\n",
    "    W = pinvEcuacionesNormales(X_train, None, transpuesta(Y_train))\n",
    "    end_time = time.perf_counter()\n",
    "    Cholesky_time = end_time - start_time\n",
    "    print(f\"Cholesky exercise executed in: {Cholesky_time:.4f} seconds\")\n",
    "    Cholesky_accuracy = validate_transferlearning(W,X_val,Y_val)\n",
    "    print(\"W shape\", W.shape)\n",
    "    print(\"X_val shape\", X_val.shape)\n",
    "    print(\"Y_val shape\", Y_val.shape)\n",
    "    matriz_confusion(W, X_val, Y_val)"
   ],
   "id": "7ac9204e3042edd4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "    #SVD\n",
    "    print(\"running svd...\")\n",
    "    start_time = time.perf_counter()\n",
    "    U, S, V = svd_reducida(X_train)\n",
    "    W_SVD = pinvSVD(U, S, V, Y_train)\n",
    "    end_time = time.perf_counter()\n",
    "    SVD_time = end_time - start_time\n",
    "    print(f\"SVD exercise executed in: {SVD_time:.4f} seconds\")\n",
    "    SVD_accuracy = validate_transferlearning(W_SVD,X_val,Y_val)\n",
    "    matriz_confusion(W_SVD, X_val, Y_val)\n"
   ],
   "id": "e0f2d420f4f705df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "    #QR\n",
    "    print(\"running qr gs...\")\n",
    "    start_time = time.perf_counter()\n",
    "    Y_train_T = transpuesta(Y_train)\n",
    "    X_train_T = transpuesta(X_train)\n",
    "    Q, R = QR_con_GS(X_train_T)\n",
    "    W_GS =  pinvGramSchmidt(Q, R, Y_train_T)\n",
    "    print(\"W_GS shape\", W_GS.shape)\n",
    "    print(\"X_val shape\", X_val.shape)\n",
    "    print(\"Y_val shape\", Y_val.shape)\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    GS_time = end_time - start_time\n",
    "    print(f\"GS exercise executed in: {GS_time:.4f} seconds\")\n",
    "    GS_accuracy = validate_transferlearning(W_GS,X_val,Y_val)\n",
    "    matriz_confusion(W_GS, X_val, Y_val)"
   ],
   "id": "75fc817290f3dd92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "    #QR\n",
    "    print(\"running qr hh...\")\n",
    "    start_time = time.perf_counter()\n",
    "    Y_train_T = transpuesta(Y_train)\n",
    "    X_train_T = transpuesta(X_train)\n",
    "    Q, R = QR_con_HH(X_train_T)\n",
    "    W_HH =  pinvHouseHolder(Q, R, Y_train_T)\n",
    "    print(\"W_HH shape\", W_HH.shape)\n",
    "    print(\"X_val shape\", X_val.shape)\n",
    "    print(\"Y_val shape\", Y_val.shape)\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    HH_time = end_time - start_time\n",
    "    print(f\"HH exercise executed in: {HH_time:.4f} seconds\")\n",
    "    HH_accuracy = validate_transferlearning(W_HH,X_val,Y_val)\n",
    "    matriz_confusion(W_HH, X_val, Y_val)"
   ],
   "id": "566550dfc86a9ed8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "    print(\"\\n\" + \"--- Tablas de resultados ---\".center(45))\n",
    "    print(\"Algoritmo |       Tiempo      | Accuracy |\")\n",
    "    print(\"-\" * 42)\n",
    "    print(f\"SVD       | 4936.3592 seconds |  68.40%  |\")\n",
    "    print(\"-\" * 42)\n",
    "    print(f\"QR-GS     |   22.5347 seconds |  68.40%  |\")\n",
    "    print(\"-\" * 42)\n",
    "    print(f\"QR-HH     |  307.5608 seconds |  68.40%  |\")\n",
    "    print(\"-\" * 42)\n",
    "    print(f\"CHL       |   43.2527 seconds |  68.40%  |\")\n",
    "    print(\"-\" * 42)\n",
    "    print(\"\\n\")"
   ],
   "id": "7eb0dcb06a64a59a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "Los resultados muestran un marcado contraste en los tiempos de ejecución: el método de Cholesky (CHL) resolvió el problema completo en menos de 43 segundos, resultando visiblemente más eficiente que las otras alternativas. QR-HH y QR-GS registraron tiempos sensiblemente mayores (en el orden de los 970 a 1.200 segundos), pero aún así más rápidos que SVD, que empleó alrededor de 4.900 segundos en encontrar la solución. SVD implica computaciones intensivas debido a el costo de calcular cada uno de los valores singulares mediante reflexiones de Householder, lo que lo hace costoso para matrices de gran tamaño o cuando pueden garantizarse otras propiedades en los datos.\n",
    "\n",
    "En los resultados de nuestras simulaciones no hubo ninguna diferencia en términos de presicion. Es de nuestro entendimiento que las metodologías presentan diferentes grados de robustez aunque no pudimos testearlos de forma acorde. En base a nuestra investigación, numpy utiliza SVD para calcular la pseudoinversa debido a su mayor robustez para matrices mal condicionadas pero para el cálculo de la misma utiliza bibliotecas como lapack que facilitan y hacen mucho más rápido el cálculo o estimación de valores singulares. La forma en la que aplicamos SVD en nuestro código no aprovecha estos métodos, lo cual lo hace marcadamente lento a comparación de los otros métodos.\n",
    "\n",
    "Las metodologías relacionadas a la descomposición QR terminaron siendo costosas por calcular la inversa de la traspuesta de la matriz R y divergieron un poco en el cálculo de la descomposición. En el caso de la descomposición utilizando Householder, la multiplicación de todas las matrices de reflexión, en conjunto con el costo de obtención de las mismas y la resolucion del sistema para obtener Q, resultaron más costosas que los cómputos necesarios para resolver R, la ortogonalización de sus vectores y la resolución de Q, siendo estas las únicas diferencias que terminaron impactando en los tiempos de resolucion, siendo el tiempo necesario para la variante dependiente de Householder 0.23 veces mayor a la variante dependiente de Gram-Schmidt.\n",
    " \n",
    "El método de Cholesky resultó ampliamente superior en cuanto a tiempos de ejecución, ubicándose como el método más eficiente dentro de nuestra comparación, manteniendo la misma precisión que las alternativas evaluadas. Si bien su aplicabilidad está condicionada a que la matriz X sea simétrica definida positiva o asumir el costo de convertirla en tal, su implementación en Python resulta directa y práctica. De acuerdo a nuestras pruebas, este método proporcionó el desempeño más favorable, por lo que si las condiciones lo permiten, preferiríamos su utilización."
   ],
   "id": "8a61994503b8de42"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
