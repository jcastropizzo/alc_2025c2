# -*- coding: utf-8 -*-
"""Copy of alc.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CuropEpc_S_GrgSgv1zC3fAyXuvpqPbB
"""

import numpy as np
from pathlib import Path
import math #para sqrt en labo8
import ctypes
import sys
import os
import time   

def debugPrint(*args, **kwargs):
    """Imprime mensajes de debug solo si la variable de entorno DEBUG está configurada."""
    if os.getenv('DEBUG'):
        print(*args, **kwargs)


def esCuadrada(A):
  return A.shape[0] == A.shape[1]

def triangSup(A):
  U = A.copy()
  for i in range(0,U.shape[0]):
    for j in range(0, U.shape[1]):
      if(i>=j):
        U[i,j] = 0
  return U

def triangInf(A):
  L = A.copy()
  for i in range(0,L.shape[0]):
    for j in range(0, L.shape[1]):
      if(i<=j):
        L[i,j] = 0
  return L

def diagonal(A):
  D = A.copy()
  for i in range(0,D.shape[0]):
    for j in range(0, D.shape[1]):
      if(i != j):
        D[i,j] = 0
  return D

def rango_R(A):
  res = 0
  for i in range(0, A.shape[0]):
    if i < A.shape[1]:
      if A[i,i] != 0:
        res += 1
      else:
        res -= 1
  return res

def traza(A):
  traza = 0
  for i in range(0,A.shape[0]):
    traza = traza + A[i,i]
  return traza

def transpuesta(A):
  debugPrint(f"[DEBUG] transpuesta: Calculando transpuesta de matriz con forma {A.shape}")
  T = np.zeros((A.shape[1],A.shape[0]))
  for i in range(0,T.shape[0]):
    for j in range(0, T.shape[1]):
      T[i,j] = A[j,i]
  debugPrint(f"[DEBUG] transpuesta: Forma del resultado {T.shape}")
  return T

def esSimetrica(A):
  T = transpuesta(A)
  if(A.shape != T.shape): return False
  for i in range(0,A.shape[0]):
    for j in range(0, A.shape[1]):
      if(A[i,j] != T[i,j]): return False
  return True

# Uso lo que tengo en aux.c
def calcularAxFast(A,x):
  pass

def matMulFast(A, B):
  raise Exception("Was not able to use C lib")
  

def calcularAx(A,x):
  res = np.zeros(A.shape[0])
  for i in range(0, A.shape[0]):
    for j in range(0, A.shape[1]):
      res[i] = res[i] + A[i,j]*x[j]
  return res

def intercambiarFilas(A,i,j):
  filai = A[i].copy()
  filaj = A[j].copy()
  A[i] = filaj
  A[j] = filai
  return A

def sumar_fila_multiplo(A,i,j,s):
  A[i] = A[i] + (A[j]*s)
  return A

def esDiagonalmenteDominante(A):
  for i in range(A.shape[0]):
    absFila = 0
    absDiagonal = abs(A[i,i])
    for j in range(A.shape[1]):
      if(i != j):
        absFila = absFila + abs(A[i,j])
    if(absFila >= absDiagonal):
      return False
  return True

def matrizCirculante(v):
  A = np.zeros((v.shape[0],v.shape[0]))
  for i in range(0,v.shape[0]):
    for j in range(0, v.shape[0]):
      A[i,j] = v[(i + j) % v.shape[0]]
  return A

def matrizVandermonde(v):
  A = np.zeros((v.shape[0],v.shape[0]))
  for i in range(0, v.shape[0]):
    A[i] = v**i
  return A

def error(x, y):
    return abs(float(x) - float(y))

def error_relativo(x,y):
  if(x == 0): return 0.
  return abs(abs(float(x) - float(y)) / float(x))

def sonIguales(x,y,atol=1e-08):
    return np.allclose(error(x,y),0,atol=atol)

def matricesIguales(A, B, tol = np.finfo(np.double).eps * 2):
    if((len(A) != len(B)) | (len(A[0]) != len(B[0]))):
      raise Exception("Matrices have different dimension, can't compare equality.")

    for ra,rb in zip(A,B):
        for a,b in zip(ra,rb):
            if not sonIguales(a,b):
                return False
    return True

def filasIguales(A, B, tol = np.finfo(np.double).eps * 2):
  if(len(A) != len(B)):
    raise Exception("Matrices have different dimension, can't compare equality.")
  for a,b in zip(A,B):
    if not sonIguales(a,b):
                return False
  return True

def matMul(A,B):
  debugPrint(f"[DEBUG] matMul: Multiplicando matrices A{A.shape} x B{B.shape}")
  if(len(A[0]) != len(B)):
    raise Exception("Matrices dimensions don't match for multiplication")
  res = np.zeros((A.shape[0],B.shape[1]))
  for i in range(0,res.shape[1]):
    res[:,i] = calcularAxFast(A,B[:,i])
  debugPrint(f"[DEBUG] matMul: Forma del resultado {res.shape}")
  return res

def matMulSlow(A,B):
  if(len(A[0]) != len(B)):
    raise Exception("Matrices dimensions don't match for multiplication")
  res = np.zeros((A.shape[0],B.shape[1]))
  for i in range(0,res.shape[1]):
    res[:,i] = calcularAx(A,B[:,i])
  return res   

def rota(theta):
  return np.array([[np.cos(theta),-np.sin(theta)],[np.sin(theta),np.cos(theta)]])

def escala(s):
  return np.eye(len(s))*s

def rota_y_escala(theta,s):
  return matMul(escala(s),rota(theta))

def afin(theta,s,b):
  mat = rota_y_escala(theta,s)

  res = np.zeros((3,3))
  for i in range(2):
      for j in range(2):
          res[i][j] = mat[i][j]

  res[0][2] = b[0] # mejorable
  res[1][2] = b[1]
  res[2][2] = 1
  return res

def trans_afin(v , theta , s , b):
    matriz_afin = afin(theta , s , b)
    vec = [v[0], v[1], 1]
    resultado = calcularAx(matriz_afin, vec)
    return [resultado[0], resultado[1]]

def norma(x,p):
  if(p == 'inf'):
    return np.max(np.abs(x))
  return np.sum(np.abs(x)**p)**(1/p)

def normaExacta(A, p):
  if p == 1:
    return np.max(np.sum(np.abs(A), axis=0))
  if p == 'inf':
    return np.max(np.sum(np.abs(A), axis=1))
  return None

def normaMatMC(A, q, p, Np):
  # 1. Crear los Np vectores aleatorios (Np filas, A.shape[1] columnas)
  mc = np.random.rand(Np, A.shape[1])

  # 2. Normalizar *toda la matriz* de vectores
  #    Calculamos la norma-p para cada fila (axis=1)
  if p == 'inf':
    norms = np.max(np.abs(mc), axis=1)
  else:
    norms = np.sum(np.abs(mc)**p, axis=1)**(1/p)

  #    Dividimos cada fila por su norma.
  #    (Usamos norms[:, np.newaxis] para que la división sea (Np, 1) y funcione por filas)
  #    Manejar división por cero si alguna norma es 0
  norms[norms == 0] = 1 
  mc_normalized = mc / norms[:, np.newaxis]

  # 3. Multiplicar A por *todos* los vectores a la vez
  #    A es (M, N). mc_normalized.T (transpuesta) es (N, Np)
  #    El resultado 'Y' es (M, Np). Cada columna de Y es un resultado A*x
  Y = A @ mc_normalized.T

  # 4. Calcular la norma-q de *todos* los Np vectores resultado (columnas de Y)
  if q == 'inf':
    candidate_norms = np.max(np.abs(Y), axis=0) # axis=0 para operar por columnas
  else:
    candidate_norms = np.sum(np.abs(Y)**q, axis=0)**(1/q)

  # 5. Encontrar la norma máxima y el índice del vector que la produjo
  normaMat = np.max(candidate_norms)
  max_index = np.argmax(candidate_norms)
  vec = mc_normalized[max_index, :] # El vector de entrada normalizado

  return [normaMat, vec]

def condMC(A,p,Np=10000):
  A_inv = np.linalg.inv(A)
  norma_A = normaMatMC(A,p,p,Np)
  norma_A_Inv = normaMatMC(A_inv,p,p,Np)
  return norma_A[0] * norma_A_Inv[0]

def condExacto(A,p):
  A_inv = np.linalg.inv(A)
  norma_A = normaExacta(A,p)
  norma_A_Inv = normaExacta(A_inv,p)
  return norma_A*norma_A_Inv

def calculaLU(A):
    debugPrint(f"[DEBUG] calculaLU: Iniciando descomposición LU para matriz de forma {A.shape}")
    cant_op = 0
    m = A.shape[0]
    n = A.shape[1]
    Ac = A.copy()
    if m != n:
        print("Matriz no cuadrada")
        return None

    debugPrint(f"[DEBUG] calculaLU: Realizando eliminación gaussiana en matriz {m}x{n}")
    for i in range(m):
        if i % 100 == 0:
            debugPrint(f"[DEBUG] calculaLU: Procesando fila {i}/{m}")
        for j in range(i + 1, m):
            if Ac[i, i] == 0:
                return None, None, 0
            pivot = Ac[j, i] / Ac[i, i]
            for k in range(i, n):
                Ac[j, k] = Ac[j, k] - pivot * Ac[i, k]
                cant_op = cant_op + 2
            Ac[j, i] = pivot

    debugPrint(f"[DEBUG] calculaLU: Extrayendo matrices L y U")
    U = np.zeros((m, n))
    L = np.eye(m)
    zerorow = np.zeros(U.shape[1])
    for i in range(m):
        for j in range(n):
            if i <= j:
                U[i, j] = Ac[i, j]
            if i > j:
                L[i, j] = Ac[i, j]
        if filasIguales(zerorow, U[i, :]):
            return None, None, 0
    
    debugPrint(f"[DEBUG] calculaLU: Completado. Cantidad de operaciones: {cant_op}")
    return L, U, cant_op

def res_tri(L,b,inferior=True):
  res = np.zeros(b.shape[0])
  if(inferior):
    res[0] = b[0]/L[0,0]
    for i in range(1,L.shape[0]):
      xb = res*L[i,:]
      sum = 0
      for j in range(xb.shape[0]):
         sum = sum + xb[j]
      res[i]=(b[i]-sum)/L[i,i]
  if(not inferior):
    n = L.shape[0]
    res[n-1] = b[n-1]/L[n-1,n-1]
    for i in reversed(range(n-1)):
      xb = res*L[i,:]
      sum = 0
      for j in range(xb.shape[0]):
         sum = sum + xb[j]
      res[i]=(b[i]-sum)/L[i,i]
  return res


def inversa(A):
    debugPrint(f"[DEBUG] inversa: Calculando inversa de matriz con forma {A.shape}")
    
    debugPrint(f"[DEBUG] inversa: Paso 1 - Calculando descomposición LU")
    L, U, _ = calculaLU(A)
    
    if L is None and U is None:
        debugPrint(f"[DEBUG] inversa: Descomposición LU falló, retornando None")
        return None
    
    debugPrint(f"[DEBUG] inversa: Paso 2 - Creando matriz identidad")
    I = np.eye(L.shape[0])

    x = np.zeros_like(L)
    debugPrint(f"[DEBUG] inversa: Paso 3 - Resolviendo {x.shape[0]} sistemas triangulares inferiores (Lx=I)")
    for i in range(x.shape[0]):
        if i % 100 == 0:
            debugPrint(f"[DEBUG] inversa: Progreso sistemas triangulares inferiores: {i}/{x.shape[0]}")
        x[:, i] = res_tri(L, I[:, i])
    
    res = np.zeros_like(A)
    debugPrint(f"[DEBUG] inversa: Paso 4 - Resolviendo {res.shape[1]} sistemas triangulares superiores (Ures=x)")
    for i in range(res.shape[1]):
        if i % 100 == 0:
            debugPrint(f"[DEBUG] inversa: Progreso sistemas triangulares superiores: {i}/{res.shape[1]}")
        res[:, i] = res_tri(U, x[:, i], inferior=False)
    
    debugPrint(f"[DEBUG] inversa: Completado. Forma del resultado {res.shape}")
    return res


def calculaLDV(A):
  L, U, nops1 = calculaLU(A)
  if(U is None): return None,None,None,None
  V_T, D, nops2 = calculaLU(transpuesta(U))
  V = transpuesta(V_T)
  return L, D, V, nops1 + nops2

def esSDP(A,atol=1e-10):
  L,D,V,_=calculaLDV(A)
  if(L is None): return False
  if(not matricesIguales(transpuesta(L),V,tol=atol)): return False
  for i in range(D.shape[0]):
    if(D[i,i] <= 0): return False
  return True

def obtener_householder(A):
    """
    A partir de una matriz A, obtiene todas las matrices de reflexión de Householder
    necesarias para triangularizarla (factorización QR mediante Householder).

    Argumentos:
    A (np.array): La matriz de entrada (m x n).

    Devuelve:
    list: Lista de matrices de Householder H_1, H_2, ..., H_k
          donde k = min(m, n)
    """
    debugPrint(f"[DEBUG] obtener_householder: Iniciando para matriz de forma {A.shape}")
    m, n = A.shape
    A_trabajo = A.copy().astype(float)
    matrices_householder = []

    # Iteramos sobre cada columna (hasta min(m, n))
    k = min(m, n)
    debugPrint(f"[DEBUG] obtener_householder: Se calcularán {k} matrices de Householder")

    for j in range(k):
        if j % 100 == 0:
            debugPrint(f"[DEBUG] obtener_householder: Procesando columna {j}/{k}")
        # Extraemos la subcolumna desde la fila j hasta el final
        x = A_trabajo[j:, j].copy().flatten()
        dim_sub = len(x)

        # Calculamos la norma del vector
        norma_x = np.linalg.norm(x)

        # Si la norma es muy pequeña, usamos la identidad
        if norma_x < 1e-10:
            H_j = np.eye(m)
            matrices_householder.append(H_j)
            continue

        # Vector canónico e_1 de la dimensión apropiada
        e1 = np.zeros(dim_sub)
        e1[0] = 1.0

        # Vector de reflexión: v = x +/- ||x|| * e_1
        # Usamos el signo apropiado para evitar cancelación catastrófica
        signo = 1.0 if x[0] >= 0 else -1.0
        v = x + signo * norma_x * e1

        # Calculamos la norma cuadrada de v para la fórmula
        v_norma_cuadrada = np.dot(v, v)

        if v_norma_cuadrada < 1e-10:
            # Si v es muy pequeño, usamos identidad
            H_sub = np.eye(dim_sub)
        else:
            # Matriz de Householder reducida: H_sub = I - 2*v*v^T/(v^T*v)
            # Usando numpy para este producto
            vv_T = np.outer(v, v)
            H_sub = np.eye(dim_sub) - 2.0 * vv_T / v_norma_cuadrada

        # Construimos la matriz de Householder completa (m x m)
        H_j = np.eye(m)
        H_j[j:, j:] = H_sub

        matrices_householder.append(H_j)

        # Aplicamos la transformación a la matriz de trabajo
        A_trabajo = np.dot(H_j, A_trabajo)

    debugPrint(f"[DEBUG] obtener_householder: Completado, generadas {len(matrices_householder)} matrices")
    return matrices_householder


def QR_con_HH(A):
    """
    Realiza la factorización QR de una matriz A usando reflexiones de Householder.

    Argumentos:
    A (np.array): La matriz de entrada (m x n).

    Devuelve:
    Para matrices no cuadradas:
      A (m x n)
      si m >= n: devuelve Q (m x n) con columnas ortonormales, R (n x n) triangular superior
      si m < n: devuelve Q (m x m) ortogonal, R (m x n) triangular superior
    tal que A = Q * R
    """
    debugPrint(f"[DEBUG] QR_con_HH: Iniciando descomposición QR con Householder para matriz de forma {A.shape}")
    m, n = A.shape
    
    debugPrint(f"[DEBUG] QR_con_HH: Calculando matrices de Householder")
    matrices_H = obtener_householder(A)
    
    debugPrint(f"[DEBUG] QR_con_HH: Obtenidas {len(matrices_H)} matrices de Householder")
    debugPrint(f"[DEBUG] QR_con_HH: Calculando matriz R")
    R = A.copy().astype(float)
    for H in matrices_H:
        R = np.dot(H, R)

    debugPrint(f"[DEBUG] QR_con_HH: Calculando matriz Q")
    Q = np.eye(m)
    for H in matrices_H:
        Q = np.dot(Q, H)

    if m >= n:
        Q = Q[:, :n]
        R = R[:n, :]

    debugPrint(f"[DEBUG] QR_con_HH: Completado. Forma Q: {Q.shape}, Forma R: {R.shape}")
    return Q, R


def QR_con_GS(A, tol=1e-12, retorna_nops=False):
    debugPrint(f"[DEBUG] QR_con_GS: Iniciando descomposición QR con Gram-Schmidt para matriz de forma {A.shape}")
    nops = 0
    m, n = A.shape

    # Para matriz tall (m > n): Q es (m × n), R es (n × n)
    # Para matriz wide (m < n): Q es (m × m), R es (m × n)
    # Para matriz cuadrada (m = n): Q es (m × m), R es (m × n)

    if m >= n:
        # Caso tall o cuadrada: Q (m × n) con columnas ortonormales, R (n × n)
        Q = np.zeros((m, n))
        R = np.zeros((n, n))
        max_cols = n
        debugPrint(f"[DEBUG] QR_con_GS: Caso matriz tall/cuadrada. Q será ({m}, {n}), R será ({n}, {n})")
    else:
        # Caso wide: Q (m × m) ortogonal, R (m × n)
        Q = np.zeros((m, m))
        R = np.zeros((m, n))
        max_cols = m
        debugPrint(f"[DEBUG] QR_con_GS: Caso matriz wide. Q será ({m}, {m}), R será ({m}, {n})")

    debugPrint(f"[DEBUG] QR_con_GS: Calculando base ortonormal")
    R[0, 0] = norma(A[:, 0], 2)
    Q[:, 0] = A[:, 0] / R[0, 0]

    for j in range(1, max_cols):
        Q[:, j] = A[:, j]
        for k in range(0, j):
            R[k, j] = np.dot(Q[:, k], Q[:, j])
            Q[:, j] = Q[:, j] - R[k, j] * Q[:, k]
            nops = nops + 4 * m
        R[j, j] = norma(Q[:, j], 2)
        Q[:, j] = Q[:, j] / R[j, j]
        nops = nops + m

    # Para matriz wide, calcular columnas restantes de R
    if m < n:
        debugPrint(f"[DEBUG] QR_con_GS: Calculando columnas restantes de R para matriz wide")
        for j in range(max_cols, n):
            for i in range(max_cols):
                R[i, j] = np.dot(Q[:, i], A[:, j])
                nops = nops + 2 * m

    debugPrint(f"[DEBUG] QR_con_GS: Completado. Forma Q: {Q.shape}, Forma R: {R.shape}")
    if retorna_nops:
        return Q, R, nops
    else:
        return Q, R


def metpot2k(A, tol=1e-15, max_iter=1000):
    """
    Calcula el autovalor dominante (de mayor magnitud) y su autovector
    correspondiente usando el método de la potencia cuadrado (iterando con A^2).

    Argumentos:
    A (np.array): La matriz de entrada (n x n).
    tol (float): Tolerancia para la convergencia.
    max_iter (int/float): Número máximo de iteraciones.

    Devuelve:
    (v, l, k):
      v: El autovector dominante (vector columna n x 1).
      l: El autovalor dominante (escalar).
      k: El número de iteraciones realizadas.
    """
    n = A.shape[0]
    #casos base
    if n == 0:
        return np.array([]).reshape(0,1), 0.0, 0
    if n == 1:
        return np.array([[1.0]]), A[0,0], 0

    v = np.random.rand(n, 1)
    v = v / norma(v,2)

    l_prev = 0.0

    max_iter = int(max_iter)

    for k in range(max_iter):
        w = matMul(A,(matMul(A,v)))
        norma_w = norma(w,2)
        if norma_w < tol:
            return v, 0.0, k

        v_nuevo = w / norma_w
        l_nuevo = matMul(transpuesta(v_nuevo),matMul(A,v_nuevo))[0, 0]

        if np.abs(l_nuevo - l_prev) < tol:
            return v_nuevo, l_nuevo, k

        v = v_nuevo
        l_prev = l_nuevo

    print(f"El método no convergió después de {max_iter} iteraciones.")
    return v, l_nuevo, max_iter


def aplica_H_derecha(A, u_vec, u_norma_sq):
    """
    Calcula A_new = A @ H de forma eficiente en O(n^2).
    H = I - 2*u*u.T / u_norma_sq
    A_new = A @ (I - 2*u*u.T / u_norma_sq)
    A_new = A - (A @ u) @ (2 * u.T / u_norma_sq)
    """
    if u_norma_sq < 1e-20:
        return A

    # (m, n) @ (n, 1) -> (m, 1)
    Au = matMul(A, u_vec)
    # (1, n)
    ut = transpuesta(u_vec)
    # scalar
    const = 2.0 / u_norma_sq

    # (m, 1) @ (1, n) -> (m, n)
    termino = matMul(Au, ut) * const
    return A - termino


def aplica_H_izquierda(A, u_vec, u_norma_sq):
    """
    Calcula A_new = H @ A de forma eficiente en O(n^2).
    H = I - 2*u*u.T / u_norma_sq
    A_new = (I - 2*u*u.T / u_norma_sq) @ A
    A_new = A - (2 * u / u_norma_sq) @ (u.T @ A)
    """
    if u_norma_sq < 1e-20:
        return A

    # (1, n) @ (n, m) -> (1, m)
    u_t_A = matMul(transpuesta(u_vec), A)
    # scalar
    const = 2.0 / u_norma_sq

    # (n, 1) @ (1, m) -> (n, m)
    termino = matMul(u_vec, u_t_A) * const
    return A - termino


def diagRH(A_original, tol=1e-15, K=1000):
    """
    Diagonaliza A (simétrica) usando deflación de Householder
    de forma iterativa y eficiente (O(n^3)).
    """
    n = A_original.shape[0]

    # Manejar casos borde
    if n == 0:
        return np.array([]).reshape(0, 0), np.array([]).reshape(0, 0)
    if n == 1:
        return np.eye(1), np.copy(A_original)

    D = np.zeros((n, n))
    S_final = np.eye(n)
    B = np.copy(A_original)  # B es la matriz de trabajo que será deflacionada

    for i in range(n):
        # 1. Definir el subproblema actual B[i:, i:]
        A_sub = B[i:, i:]
        n_sub = A_sub.shape[0]

        # 2. Encontrar autovalor/autovector dominante del subproblema
        if(i % 100 == 0):# Loop n veces
            print(f"Calculando metpot {i}/{n} con dimension {A_sub.shape}...")
        (autovector_sub, autovalor, k) = metpot2k(A_sub, tol, K)
        D[i, i] = autovalor

        if n_sub == 1:
            break  # Es el último elemento, no hay más que deflacionar

        # 3. Construir el vector u para la reflexión de Householder
        e_0 = np.zeros((n_sub, 1))
        e_0[0] = 1.0

        if autovector_sub.shape[1] != 1:
            autovector_sub = autovector_sub.reshape(-1, 1)

        # Fórmula numéricamente estable para u
        norma_v = norma(autovector_sub, 2)
        sign_v0 = 1.0 if autovector_sub[0, 0] >= 0 else -1.0
        u_sub = autovector_sub + sign_v0 * norma_v * e_0
        u_norma_sq = norma(u_sub, 2) ** 2

        if u_norma_sq < tol:
            # El autovector ya es e_0, no se necesita reflexión
            continue

        # 4. "Embed" u_sub en un vector de tamaño completo n
        u_full = np.zeros((n, 1))
        u_full[i:] = u_sub

        # 5. Acumular S_final = S_final @ H_full (Operación O(n^2))
        S_final = aplica_H_derecha(S_final, u_full, u_norma_sq)

        # 6. Deflacionar B = H_full @ B @ H_full (Operación O(n^2))
        # H es simétrica (H = H.T)
        B = aplica_H_izquierda(B, u_full, u_norma_sq)
        B = aplica_H_derecha(B, u_full, u_norma_sq)
    return (S_final, D)

def transiciones_al_azar_continuas(n):
    """
    n la cantidad de filas (columnas) de la matriz de transición.
    Retorna matriz T de n x n normalizada por columnas, y con entradas al azar en el intervalo [0,1]
    """
    T = np.random.rand(n,n)
    for i in range(n):
      T[:,i] = T[:,i]/norma(T[:,i],1)
    return T

def transiciones_al_azar_uniformes(n,thres):
    """
    n la cantidad de filas (columnas) de la matriz de transición.
    thres probabilidad de que una entrada sea distinta de cero.
    Retorna matriz T de n x n normalizada por columnas.
    El elemento i,j es distinto de cero si el número generado al azar para i,j es menor o igual a thres.
    Todos los elementos de la columna $j$ son iguales
    (a 1 sobre el número de elementos distintos de cero en la columna).
    """
    T = (np.random.rand(n,n) < 0.3).astype(float)
    for i in range(n):
      norm=norma(T[:,i],1)
      if(norm != 0):
          T[:,i] = T[:,i]/norm
      else:
          T[np.random.randint(0,n),i] = 1.
    return T

def nucleo(A,tol=1e-15):
    """
    A una matriz de m x n
    tol la tolerancia para asumir que un vector esta en el nucleo.
    Calcula el nucleo de la matriz A diagonalizando la matriz traspuesta(A) * A (* la multiplicacion matricial), usando el medodo diagRH. El nucleo corresponde a los autovectores de autovalor con modulo <= tol.
    Retorna los autovectores en cuestion, como una matriz de n x k, con k el numero de autovectores en el nucleo.
    """
    diag =  diagRH(matMul(transpuesta(A),A),tol,1000)
    mascara_cero = np.isclose(np.diag(diag[1]), 0, atol=tol)
    return (diag[0])[:, mascara_cero]


def crea_rala(listado,m_filas,n_columnas,tol=1e-15):
    """
    Recibe una lista listado, con tres elementos: lista con indices i, lista con indices j, y lista con valores A_ij de la matriz A. Tambien las dimensiones de la matriz a traves de m_filas y n_columnas. Los elementos menores a tol se descartan.
    Idealmente, el listado debe incluir unicamente posiciones correspondientes a valores distintos de cero. Retorna una lista con:
    - Diccionario {(i,j):A_ij} que representa los elementos no nulos de la matriz A. Los elementos con modulo menor a tol deben descartarse por default.
    - Tupla (m_filas,n_columnas) que permita conocer las dimensiones de la matriz.
    """
    matriz = {}
    if(len(listado) != 0):
      for i,j,aij in zip(listado[0],listado[1],listado[2]):
        if(abs(aij) >= tol):
            matriz[(i,j)] = aij
    return matriz, (m_filas, n_columnas)

def multiplica_rala_vector(A,v):
    """
    Recibe una matriz rala creada con crea_rala y un vector v.
    Retorna un vector w resultado de multiplicar A con v
    """
    b = np.zeros_like(v)

    for elem in A[0].keys():
         b[elem[0]] = b[elem[0]] + A[0][elem]*v[elem[1]]
    return b

def es_markov(T,tol=1e-6):
    """
    T una matriz cuadrada.
    tol la tolerancia para asumir que una suma es igual a 1.
    Retorna True si T es una matriz de transición de Markov (entradas no negativas y columnas que suman 1 dentro de la tolerancia), False en caso contrario.
    """
    n = T.shape[0]
    for i in range(n):
        for j in range(n):
            if T[i,j]<0:
                return False
    for j in range(n):
        suma_columna = sum(T[:,j])
        if np.abs(suma_columna - 1) > tol:
            return False
    return True

def es_markov_uniforme(T,thres=1e-6):
    """
    T una matriz cuadrada.
    thres la tolerancia para asumir que una entrada es igual a cero.
    Retorna True si T es una matriz de transición de Markov uniforme (entradas iguales a cero o iguales entre si en cada columna, y columnas que suman 1 dentro de la tolerancia), False en caso contrario.
    """
    if not es_markov(T,thres):
        return False
    # cada columna debe tener entradas iguales entre si o iguales a cero
    m = T.shape[1]
    for j in range(m):
        non_zero = T[:,j][T[:,j] > thres]
        # all close
        close = all(np.abs(non_zero - non_zero[0]) < thres)
        if not close:
            return False
    return True

def esNucleo(A,S,tol=1e-5):
    """
    A una matriz m x n
    S una matriz n x k
    tol la tolerancia para asumir que un vector esta en el nucleo.
    Retorna True si las columnas de S estan en el nucleo de A (es decir, A*S = 0. Esto no chequea si es todo el nucleo
    """
    for col in S.T:
        res = A @ col
        if not np.allclose(res,np.zeros(A.shape[0]), atol=tol):
            return False
    return True


def cholesky(A):
    """
    Realiza la descomposición de Cholesky de una matriz simétrica y definida positiva A.
    Retorna una matriz L tal que A = L * L^T
    """
    n = A.shape[0]
    L = np.zeros_like(A)

    for i in range(n):
        for j in range(i + 1):
            if i == j:
                L[i, j] = np.sqrt(A[i, i] - np.sum(L[i, :j] ** 2))
            else:
                L[i, j] = (A[i, j] - np.sum(L[i, :j] * L[j, :j])) / L[j, j]

    return L, transpuesta(L)

def svd_reducida(A, k="max", tol=1e-15):
    """
    A la matriz de interes (de m x n)
    k el numero de valores singulares (y vectores) a retener.
    tol la tolerancia para considerar un valor singular igual a cero
    Retorna hatU (matriz de m x k), hatSig (matriz diagonal de k x k) y hatV (matriz de n x k)
    """
    m, n = A.shape

    if m < n:
        print("Calculando A*AT...")
        mult_mat_start_time = time.perf_counter()
        B = matMul(A, transpuesta(A))
        mult_mat_end_time = time.perf_counter()
        mult_mat_time = mult_mat_end_time - mult_mat_start_time
        print(f"A*AT calculada en {mult_mat_time:.4f} segundos")
        diag_start = time.perf_counter()
        print("Calculando DiagRH de A*AT para obtener diagonalización")
        diagonalizacion = diagRH(B, tol,1000)
        diag_end = time.perf_counter()
        print(f"Diagonalizacion calculada en {(diag_end - diag_start)/60:.4f} minutos")
        U = diagonalizacion[0]
        D = diagonalizacion[1]
        autovalores_orig = np.diag(D)
        indices_ordenados = np.argsort(autovalores_orig)[::-1]
        autovalores_ordenados = autovalores_orig[indices_ordenados]
        U_ordenado = U[:, indices_ordenados]

        autovalores_filtrados = autovalores_ordenados[autovalores_ordenados >= tol]
        print("Calculando valores singulares")
        valores_singulares = np.sqrt(autovalores_filtrados)
        r = len(valores_singulares)

        if k == "max":
            k_eff = r
        else:
            k_eff = min(int(k), r)

        hatS = np.diag(valores_singulares[:k_eff])
        hatU = U_ordenado[:, :k_eff]

        hatV = np.zeros((A.shape[1], k_eff))
        print("Calculando B_v...")
        B_v = matMul(transpuesta(A), hatU)

        for i in range(k_eff):
            sigma_i = hatS[i, i]
            if sigma_i >= tol:
                hatV[:, i] = B_v[:, i] / sigma_i

    else: # (m >= n)
        B = matMul(transpuesta(A), A)
        diagonalizacion = diagRH(B, tol,1000)
        V = diagonalizacion[0]
        D = diagonalizacion[1]

        autovalores_orig = np.diag(D)
        indices_ordenados = np.argsort(autovalores_orig)[::-1]
        autovalores_ordenados = autovalores_orig[indices_ordenados]
        V_ordenado = V[:, indices_ordenados]

        autovalores_filtrados = autovalores_ordenados[autovalores_ordenados >= tol]
        valores_singulares = np.sqrt(autovalores_filtrados)
        r = len(valores_singulares)

        if k == "max":
            k_eff = r
        else:
            k_eff = min(int(k), r)

        hatS = np.diag(valores_singulares[:k_eff])
        hatV = V_ordenado[:, :k_eff]

        hatU = np.zeros((A.shape[0], k_eff))
        B_u = matMul(A, hatV)

        for i in range(k_eff):
            sigma_i = hatS[i, i]
            if sigma_i >= tol:
                hatU[:, i] = B_u[:, i] / sigma_i

    return hatU, hatS, hatV

try:
    # 1. Determine the correct file extension based on the OS
    if sys.platform.startswith('darwin'):
        # macOS uses .dylib or .so (but .dylib is more common for system)
        lib_ext = ".dylib"
    elif sys.platform.startswith('linux'):
        # Linux uses .so
        lib_ext = ".so"
    else:
        # Fallback for other systems (like Windows, where it would be .dll)
        # We'll stick to the provided extensions for now
        raise OSError(f"Unsupported OS for C extension: {sys.platform}")

    # 2. Construct the library path
    lib_name = "aux" + lib_ext
    
    # Use os.path.join for cross-platform path construction
    # Note: If your script is in a different location than 'aux.so', you'll need
    # to provide a full or relative path here. We assume they are together.
    lib_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), lib_name)

    # 3. Load the library
    aux = ctypes.CDLL(lib_path)
    print(f"Loaded {lib_name} ({sys.platform})")

    # 4. Find the C function
    # The author's original logic for checking the underscore prefix is kept, 
    # as macOS C compilers sometimes mangle function names with a leading underscore.
    try:
        # Try with underscore prefix (macOS convention)
        calcularAX_func = aux._calcularAX
    except AttributeError:
        # Try without underscore (Linux/standard convention)
        calcularAX_func = aux.calcularAX
    try:
        # Try with underscore prefix (macOS convention)
        matMul_func = aux._matMul
    except AttributeError:
        # Try without underscore (Linux/standard convention)
        matMul_func = aux.matMul
      
    matMul_func.argtypes = [
      ctypes.POINTER(ctypes.c_float), ctypes.POINTER(ctypes.c_float),
      ctypes.POINTER(ctypes.c_float), ctypes.c_int, ctypes.c_int, ctypes.c_int
    ]
    # 5. Configure function types (remains the same as this is C-specific)
    calcularAX_func.argtypes = [
      ctypes.POINTER(ctypes.c_float), ctypes.POINTER(ctypes.c_float),
      ctypes.POINTER(ctypes.c_float), ctypes.c_int, ctypes.c_int
    ]

    # 6. Define the Python wrapper function
    def _calcularAxFast(A,x):
      # Ensure inputs are float32 and contiguous for C compatibility
      A_f32 = np.ascontiguousarray(A, dtype=np.float32)
      x_f32 = np.ascontiguousarray(x, dtype=np.float32)
      
      n_rows = A_f32.shape[0]
      n_cols = A_f32.shape[1]
      
      # Convert numpy data buffers to C pointers
      A_ctypes = A_f32.ctypes.data_as(ctypes.POINTER(ctypes.c_float))
      x_ctypes = x_f32.ctypes.data_as(ctypes.POINTER(ctypes.c_float))
      
      # Prepare the result buffer
      res = np.zeros(n_rows, dtype=np.float32)
      res_ctypes = res.ctypes.data_as(ctypes.POINTER(ctypes.c_float))

      # Call the C function
      calcularAX_func(A_ctypes, x_ctypes, res_ctypes, n_rows, n_cols)
      return res
    
    def matMulFast(A, B):
      # Ensure inputs are float32 and contiguous for C compatibility
      A_f32 = np.ascontiguousarray(A, dtype=np.float32)
      B_f32 = np.ascontiguousarray(B, dtype=np.float32)
      
      n_rows = A_f32.shape[0]
      n_cols_A = A_f32.shape[1]
      n_cols_B = B_f32.shape[1]
      
      # Convert numpy data buffers to C pointers
      A_ctypes = A_f32.ctypes.data_as(ctypes.POINTER(ctypes.c_float))
      B_ctypes = B_f32.ctypes.data_as(ctypes.POINTER(ctypes.c_float))
      
      # Prepare the result buffer
      res = np.zeros((n_rows, n_cols_B), dtype=np.float32)
      res_ctypes = res.ctypes.data_as(ctypes.POINTER(ctypes.c_float))

      # Call the C function
      matMul_func(A_ctypes, B_ctypes, res_ctypes, n_rows, n_cols_A, n_cols_B)
      return res
    
    matMul = matMulFast
    
    # Set the public function to the fast C version
    calcularAxFast = _calcularAxFast
    print("USING FAST CODE")

# 7. Error Handling: Fallback to slow code if C loading fails
except Exception as e:
  print(f"Error loading or configuring C extension: {e}")
  print("USING SLOW CODE")
  # calcularAxFast is already set to calcularAx from the start





######################################################## EJERCICIOS TP ########################################################
#############################################################################################################################


### EJERCICIO 1

CLASSES = ["cats", "dogs"]
EMBEDDING_NAME = "efficientnet_b3_embeddings.npy"

Datos = tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]

def cargarDataset(file: Path) -> Datos:
    val_path = file / "val"
    train_path = file / "train"
    train_paths = [train_path / cls / EMBEDDING_NAME for cls in CLASSES]
    val_paths = [val_path / cls / EMBEDDING_NAME for cls in CLASSES]

    training_data = np.concatenate([np.load(path) for path in train_paths], axis=1)
    training_labels = np.array([[1, 0]] * (training_data.shape[1] // 2))
    training_labels = np.concatenate(
        [training_labels, np.array([[0, 1]] * (training_data.shape[1] // 2))], axis=0
    )

    validation_data = np.concatenate([np.load(path) for path in val_paths], axis=1)
    validation_labels = np.array([[1, 0]] * (validation_data.shape[1] // 2))
    validation_labels = np.concatenate(
        [validation_labels, np.array([[0, 1]] * (validation_data.shape[1] // 2))],
        axis=0,
    )

    return training_data, training_labels, validation_data, validation_labels

### EJERCICIO 2


"""
Dada X(n x p) ∈ R
     Y(m x p) ∈ R
1: a- Si rango(X) = p n > p
2: b- Si rango(X) = n n < p
3: c- Si rango(X) = n y n = p
4: Calcular W = Y X+
"""

def connected_con_cholesky(X, Y):
  transpose = transpuesta
  solve = np.linalg.solve
  #mul = lambda A, B: A @ B
  mul = matMul
  
  def caso1(X, Y, transpose, solve, cholesky, matmul):
    X_T = transpose(X)
    A = matmul(X_T, X)
    L, Lt = cholesky(A)
    # L * Lt * U = X_T
    # L * B = X_T
    B = solve(L, X_T)
    # Lt * U = B
    U = solve(Lt, B)
    # W = Y * U
    W = matmul(Y, U)
    return W

  # Caso 2
  # A = X * X transpuesta
  # Quiero resolver V * A = X transpuesta
  # Que es lo mismo que hacer A transpuesta * V transpuesta = X
  # despejar W de W = Y * V
  def caso2(X, Y, transpose, solve, cholesky, matmul):
    X_T = transpose(X)
    A = matmul(X, X_T)
    A_T = transpose(A)
    L, Lt = cholesky(A_T)
    B = solve(L, X)
    V_T = solve(Lt, B)
    V = transpose(V_T)
    W = matmul(Y, V)
    return W

  # Despejar W de WX = Y
  # W = Y * X+
  def caso3(X, Y, transpose, solve, cholesky, matmul):
    W = matmul(Y, inversa(X))
    return W
    
  Q,R = QR_con_GS(X)
  rank = rango_R(R)
  n = X.shape[0]
  p = X.shape[1]

  print("Rango de X:", rank)

  if rank == p and n > p:
      W = caso1(X, Y, transpose, solve, cholesky, matMul)
  elif rank == n and n < p:
      W = caso2(X, Y, transpose, solve, cholesky, matMul)
  elif rank == n and n == p:
      W = caso3(X, Y, transpose, solve, cholesky, matMul)
  else:
      raise ValueError("Rango de X no compatible con Y")
  return W

pinvEcuacionesNormales = connected_con_cholesky

### EJERCICIO 3

def inversa_diagonal(A):
    # 1. Create a writeable copy of the array A
    B = A.copy()
    for i in range(B.shape[0]):
        if B[i,i] != 0:
            B[i,i] = 1/B[i,i]
    return B

def pinvSVD(U, S, V, Y):
    n = U.shape[0]

    Ut = transpuesta(U)
    V1 = V[:,0:n]
    St = inversa_diagonal(S)

    W = matMul(matMul(matMul(transpuesta(Y),V1),St),Ut)
        
    return W
  
### EJERCICIO 4

def res_tri_mat(L, B, inferior=True):
    """
    Resuelve sistemas triangulares donde el término independiente B es una matriz.

    Args:
        L: matriz triangular (m x m)
        B: matriz (m x k) (cada columna es un lado derecho)
        inferior: True si L es triangular inferior, False si superior.

    Returns:
        X: matriz (m x k) tal que L X = B
    """
    m, k = B.shape
    X = np.zeros_like(B)
    for j in range(k):
        X[:, j] = res_tri(L, B[:, j], inferior=inferior)
    return X


def _calcular_pesos_con_qr(Q: np.ndarray, R: np.ndarray, Y: np.ndarray) -> np.ndarray:
    """
    Implementación del Algoritmo 3 para calcular la matriz de pesos W.

    Args:
        Q: Matriz con columnas ortonormales de la descomposición QR (n x n)
        R: Matriz triangular superior de la descomposición QR (n x p)
        Y: Matriz de targets de entrenamiento (n x k) donde n = n_classes y k = n_samples
 
    Returns:
        W: Matriz de pesos (n x k)

    Algoritmo 3:
        Para matriz X (n x p) con n < p:

        Derivación de la fórmula simplificada:
        1. Pseudoinversa para matriz X (n x p) con n < p:
           X⁺ = X^T @ (X @ X^T)^{-1}

        2. Usar la descomposición QR de X^T = Q @ R.
           Entonces X^T = Q @ R
           Por lo tanto, X = (Q @ R)^T = R^T @ Q^T

        3. Calcular X @ X^T:
           X @ X^T = (R^T @ Q^T) @ (Q @ R)
                   = R^T @ (Q^T @ Q) @ R
           Como Q tiene columnas ortonormales, Q^T @ Q = I,
           así que X @ X^T = R^T @ R

        4. Calcular la inversa:
           (X @ X^T)^{-1} = (R^T @ R)^{-1}

        5. Sustituir en la expresión de la pseudoinversa:
           X⁺ = X^T @ (X @ X^T)^{-1}
              = Q @ R @ (R^T @ R)^{-1}

        6. Utilizar la propiedad de la inversa de un producto:
           (R^T @ R)^{-1} = R^{-1} @ (R^T)^{-1}
           Entonces:
           X⁺ = Q @ R @ R^{-1} @ (R^T)^{-1}
              = Q @ I @ (R^T)^{-1}
              = Q @ (R^T)^{-1}
           X⁺ @ (R^T) = Q
                   
        9. Calcular pesos:
           W = Y @ X⁺
           W @ (R^T) = Y @ X⁺ @ (R^T)
           W @ (R^T) = Y @ Q
           (W @ R^T)^T = (Y @ Q)^T
           R @ W^T = (Y @ Q)^T
    """
    Y_Q_T = transpuesta(matMul(Y, Q))
    
    W_T = res_tri_mat(R, Y_Q_T, inferior=False)
    return transpuesta(W_T)


# 4.1
def pinvHouseHolder(Q: np.ndarray, R: np.ndarray, Y: np.ndarray) -> np.ndarray:
    return _calcular_pesos_con_qr(Q, R, Y)


# 4.2
def pinvGramSchmidt(Q: np.ndarray, R: np.ndarray, Y: np.ndarray) -> np.ndarray:
    return _calcular_pesos_con_qr(Q, R, Y)
  
### EJERCICIO 5
TOL = 1e-8

def esPseudoInversa(A, B, tol=TOL):
    AB = matMul(A, B)
    BA = matMul(B, A)
    cond1 = matricesIguales(matMul(AB, A), A, tol=tol)
    cond2 = matricesIguales(matMul(BA, B), B, tol=tol)
    cond3 = matricesIguales(transpuesta(AB), AB, tol=tol)
    cond4 = matricesIguales(transpuesta(BA), BA, tol=tol)
    return cond1 and cond2 and cond3 and cond4
  
### EJERCICIO 6

def matriz_confusion(W, X_val, Y_val):
    conf_mat = np.array([[0,0],[0,0]])

    samples = X_val.shape[1]
    for i in range(samples):
        y_true_vector = Y_val[i, :]
        ei = W @ X_val[:, i]
        predicted_class = np.argmax(ei)
        true_class = np.argmax(y_true_vector)
        conf_mat[true_class, predicted_class] += 1

    verdaderos_gatos = conf_mat[0, 0]
    falsos_perros = conf_mat[0, 1]  # Gatos Reales, predichos como Perros
    falsos_gatos = conf_mat[1, 0]  # Perros Reales, predichos como Gatos
    verdaderos_perros = conf_mat[1, 1]

    print("\n" + "--- Matriz de Confusión (Validación) ---".center(45))
    print(" " * 15 + "Predicción: GATO | Predicción: PERRO |")
    print(" " * 17 + "-" * 37)

    print(f"Realidad: GATO  | {verdaderos_gatos:^15} | {falsos_perros:^17} |")
    print(" " * 17 + "-" * 37)
    print(f"Realidad: PERRO | {falsos_gatos:^15} | {verdaderos_perros:^17} |")
    print(" " * 17 + "-" * 37)
    print("\n")

def validate_transferlearning(W, X_val, Y_val):
    predicciones_correctas = 0
    samples = X_val.shape[1]
    for i in range(samples):
        y_true_vector = Y_val[i, :]
        ei = W @ X_val[:, i]
        predicted_class = np.argmax(ei)
        true_class = np.argmax(y_true_vector)
        if predicted_class == true_class:
            predicciones_correctas += 1

    accuracy = (predicciones_correctas / samples) * 100
    print(f"\n--- Resultados de Validación ---")
    print(f"Precisión (Accuracy): {accuracy:.2f}%")
    print(f"Clasificó correctamente {predicciones_correctas} de {samples} muestras.")
    return accuracy