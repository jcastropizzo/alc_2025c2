# -*- coding: utf-8 -*-
"""Copy of alc.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CuropEpc_S_GrgSgv1zC3fAyXuvpqPbB
"""

import numpy as np
import math #para sqrt en labo8
import ctypes
import sys
import os
import time   

def esCuadrada(A):
  return A.shape[0] == A.shape[1]

def triangSup(A):
  U = A.copy()
  for i in range(0,U.shape[0]):
    for j in range(0, U.shape[1]):
      if(i>=j):
        U[i,j] = 0
  return U

def triangInf(A):
  L = A.copy()
  for i in range(0,L.shape[0]):
    for j in range(0, L.shape[1]):
      if(i<=j):
        L[i,j] = 0
  return L

def diagonal(A):
  D = A.copy()
  for i in range(0,D.shape[0]):
    for j in range(0, D.shape[1]):
      if(i != j):
        D[i,j] = 0
  return D

def traza(A):
  traza = 0
  for i in range(0,A.shape[0]):
    traza = traza + A[i,i]
  return traza

def transpuesta(A):
  T = np.zeros((A.shape[1],A.shape[0]))
  for i in range(0,T.shape[0]):
    for j in range(0, T.shape[1]):
      T[i,j] = A[j,i]
  return T

def esSimetrica(A):
  T = transpuesta(A)
  if(A.shape != T.shape): return False
  for i in range(0,A.shape[0]):
    for j in range(0, A.shape[1]):
      if(A[i,j] != T[i,j]): return False
  return True

# Uso lo que tengo en aux.c
def calcularAxFast(A,x):
  pass

def matMulFast(A, B):
  raise Exception("Was not able to use C lib")
  

def calcularAx(A,x):
  res = np.zeros(A.shape[0])
  for i in range(0, A.shape[0]):
    for j in range(0, A.shape[1]):
      res[i] = res[i] + A[i,j]*x[j]
  return res

def intercambiarFilas(A,i,j):
  filai = A[i].copy()
  filaj = A[j].copy()
  A[i] = filaj
  A[j] = filai
  return A

def sumar_fila_multiplo(A,i,j,s):
  A[i] = A[i] + (A[j]*s)
  return A

def esDiagonalmenteDominante(A):
  for i in range(A.shape[0]):
    absFila = 0
    absDiagonal = abs(A[i,i])
    for j in range(A.shape[1]):
      if(i != j):
        absFila = absFila + abs(A[i,j])
    if(absFila >= absDiagonal):
      return False
  return True

def matrizCirculante(v):
  A = np.zeros((v.shape[0],v.shape[0]))
  for i in range(0,v.shape[0]):
    for j in range(0, v.shape[0]):
      A[i,j] = v[(i + j) % v.shape[0]]
  return A

def matrizVandermonde(v):
  A = np.zeros((v.shape[0],v.shape[0]))
  for i in range(0, v.shape[0]):
    A[i] = v**i
  return A

def error(x, y):
    return abs(float(x) - float(y))

def error_relativo(x,y):
  if(x == 0): return 0.
  return abs(abs(float(x) - float(y)) / float(x))

def sonIguales(x,y,atol=1e-08):
    return np.allclose(error(x,y),0,atol=atol)

def matricesIguales(A, B, tol = np.finfo(np.double).eps * 2):
    if((len(A) != len(B)) | (len(A[0]) != len(B[0]))):
      raise Exception("Matrices have different dimension, can't compare equality.")

    for ra,rb in zip(A,B):
        for a,b in zip(ra,rb):
            if not sonIguales(a,b):
                return False
    return True

def filasIguales(A, B, tol = np.finfo(np.double).eps * 2):
  if(len(A) != len(B)):
    raise Exception("Matrices have different dimension, can't compare equality.")
  for a,b in zip(A,B):
    if not sonIguales(a,b):
                return False
  return True

def matMul(A,B):
  if(len(A[0]) != len(B)):
    raise Exception("Matrices dimensions don't match for multiplication")
  res = np.zeros((A.shape[0],B.shape[1]))
  for i in range(0,res.shape[1]):
    res[:,i] = calcularAxFast(A,B[:,i])
  return res

def matMulSlow(A,B):
  if(len(A[0]) != len(B)):
    raise Exception("Matrices dimensions don't match for multiplication")
  res = np.zeros((A.shape[0],B.shape[1]))
  for i in range(0,res.shape[1]):
    res[:,i] = calcularAx(A,B[:,i])
  return res   

def rota(theta):
  return np.array([[np.cos(theta),-np.sin(theta)],[np.sin(theta),np.cos(theta)]])

def escala(s):
  return np.eye(len(s))*s

def rota_y_escala(theta,s):
  return matMul(escala(s),rota(theta))

def afin(theta,s,b):
  mat = rota_y_escala(theta,s)

  res = np.zeros((3,3))
  for i in range(2):
      for j in range(2):
          res[i][j] = mat[i][j]

  res[0][2] = b[0] # mejorable
  res[1][2] = b[1]
  res[2][2] = 1
  return res

def trans_afin(v , theta , s , b):
    matriz_afin = afin(theta , s , b)
    vec = [v[0], v[1], 1]
    resultado = calcularAx(matriz_afin, vec)
    return [resultado[0], resultado[1]]

def norma(x,p):
  if(p == 'inf'):
    return np.max(np.abs(x))
  return np.sum(np.abs(x)**p)**(1/p)

def normaExacta(A, p):
  if p == 1:
    return np.max(np.sum(np.abs(A), axis=0))
  if p == 'inf':
    return np.max(np.sum(np.abs(A), axis=1))
  return None

def normaMatMC(A, q, p, Np):
  # 1. Crear los Np vectores aleatorios (Np filas, A.shape[1] columnas)
  mc = np.random.rand(Np, A.shape[1])

  # 2. Normalizar *toda la matriz* de vectores
  #    Calculamos la norma-p para cada fila (axis=1)
  if p == 'inf':
    norms = np.max(np.abs(mc), axis=1)
  else:
    norms = np.sum(np.abs(mc)**p, axis=1)**(1/p)

  #    Dividimos cada fila por su norma.
  #    (Usamos norms[:, np.newaxis] para que la división sea (Np, 1) y funcione por filas)
  #    Manejar división por cero si alguna norma es 0
  norms[norms == 0] = 1 
  mc_normalized = mc / norms[:, np.newaxis]

  # 3. Multiplicar A por *todos* los vectores a la vez
  #    A es (M, N). mc_normalized.T (transpuesta) es (N, Np)
  #    El resultado 'Y' es (M, Np). Cada columna de Y es un resultado A*x
  Y = A @ mc_normalized.T

  # 4. Calcular la norma-q de *todos* los Np vectores resultado (columnas de Y)
  if q == 'inf':
    candidate_norms = np.max(np.abs(Y), axis=0) # axis=0 para operar por columnas
  else:
    candidate_norms = np.sum(np.abs(Y)**q, axis=0)**(1/q)

  # 5. Encontrar la norma máxima y el índice del vector que la produjo
  normaMat = np.max(candidate_norms)
  max_index = np.argmax(candidate_norms)
  vec = mc_normalized[max_index, :] # El vector de entrada normalizado

  return [normaMat, vec]

def condMC(A,p,Np=10000):
  A_inv = np.linalg.inv(A)
  norma_A = normaMatMC(A,p,p,Np)
  norma_A_Inv = normaMatMC(A_inv,p,p,Np)
  return norma_A[0] * norma_A_Inv[0]

def condExacto(A,p):
  A_inv = np.linalg.inv(A)
  norma_A = normaExacta(A,p)
  norma_A_Inv = normaExacta(A_inv,p)
  return norma_A*norma_A_Inv

def calculaLU(A):
    cant_op = 0
    m=A.shape[0]
    n=A.shape[1]
    Ac = A.copy()
    if m!=n:
        print('Matriz no cuadrada')
        return None

    for i in range(m):
        for j in range(i+1,m):
            if(Ac[i,i] == 0):
              return None, None, 0
            pivot = Ac[j,i]/Ac[i,i]
            for k in range(i,n):
                Ac[j,k] = Ac[j,k]-pivot*Ac[i,k]
                cant_op = cant_op + 2
            Ac[j,i] = pivot

    U = np.zeros((m,n))
    L = np.eye(m)
    zerorow = np.zeros(U.shape[1])
    for i in range(m):
        for j in range(n):
            if(i<=j):
                U[i,j] = Ac[i,j]
            if(i>j):
                L[i,j] = Ac[i,j]
        if(filasIguales(zerorow,U[i,:])): return None, None, 0
    return L, U, cant_op

def res_tri(L,b,inferior=True):
  res = np.zeros(b.shape[0])
  if(inferior):
    res[0] = b[0]/L[0,0]
    for i in range(1,L.shape[0]):
      xb = res*L[i,:]
      sum = 0
      for j in range(xb.shape[0]):
         sum = sum + xb[j]
      res[i]=(b[i]-sum)/L[i,i]
  if(not inferior):
    n = L.shape[0]
    res[n-1] = b[n-1]/L[n-1,n-1]
    for i in reversed(range(n-1)):
      xb = res*L[i,:]
      sum = 0
      for j in range(xb.shape[0]):
         sum = sum + xb[j]
      res[i]=(b[i]-sum)/L[i,i]
  return res

def inversa(A):
  L,U,_ = calculaLU(A)
  if (L is None and U is None): return None
  I = np.eye(L.shape[0])

  x = np.zeros_like(L)
  for i in range(x.shape[0]):
    x[:,i] = res_tri(L,I[:,i])
  res = np.zeros_like(A)
  for i in range(res.shape[1]):
    res[:,i] = res_tri(U,x[:,i],inferior=False)
  return res

def calculaLDV(A):
  L, U, nops1 = calculaLU(A)
  if(U is None): return None,None,None,None
  V_T, D, nops2 = calculaLU(transpuesta(U))
  V = transpuesta(V_T)
  return L, D, V, nops1 + nops2

def esSDP(A,atol=1e-10):
  L,D,V,_=calculaLDV(A)
  if(L is None): return False
  if(not matricesIguales(transpuesta(L),V,tol=atol)): return False
  for i in range(D.shape[0]):
    if(D[i,i] <= 0): return False
  return True

def obtener_householder(A):
    """
    A partir de una matriz A, obtiene todas las matrices de reflexión de Householder
    necesarias para triangularizarla (factorización QR mediante Householder).

    Argumentos:
    A (np.array): La matriz de entrada (m x n).

    Devuelve:
    list: Lista de matrices de Householder H_1, H_2, ..., H_k
          donde k = min(m, n)
    """
    m, n = A.shape
    A_trabajo = A.copy().astype(float)
    matrices_householder = []

    # Iteramos sobre cada columna (hasta min(m, n))
    k = min(m, n)

    for j in range(k):
        # Extraemos la subcolumna desde la fila j hasta el final
        x = A_trabajo[j:, j].copy().flatten()
        dim_sub = len(x)

        # Calculamos la norma del vector
        norma_x = np.linalg.norm(x)

        # Si la norma es muy pequeña, usamos la identidad
        if norma_x < 1e-10:
            H_j = np.eye(m)
            matrices_householder.append(H_j)
            continue

        # Vector canónico e_1 de la dimensión apropiada
        e1 = np.zeros(dim_sub)
        e1[0] = 1.0

        # Vector de reflexión: v = x +/- ||x|| * e_1
        # Usamos el signo apropiado para evitar cancelación catastrófica
        signo = 1.0 if x[0] >= 0 else -1.0
        v = x + signo * norma_x * e1

        # Calculamos la norma cuadrada de v para la fórmula
        v_norma_cuadrada = np.dot(v, v)

        if v_norma_cuadrada < 1e-10:
            # Si v es muy pequeño, usamos identidad
            H_sub = np.eye(dim_sub)
        else:
            # Matriz de Householder reducida: H_sub = I - 2*v*v^T/(v^T*v)
            # Usando numpy para este producto
            vv_T = np.outer(v, v)
            H_sub = np.eye(dim_sub) - 2.0 * vv_T / v_norma_cuadrada

        # Construimos la matriz de Householder completa (m x m)
        H_j = np.eye(m)
        H_j[j:, j:] = H_sub

        matrices_householder.append(H_j)

        # Aplicamos la transformación a la matriz de trabajo
        A_trabajo = np.dot(H_j, A_trabajo)

    return matrices_householder


def QR_con_HH(A):
    """
    Realiza la factorización QR de una matriz A usando reflexiones de Householder.

    Argumentos:
    A (np.array): La matriz de entrada (m x n).

    Devuelve:
    (Q, R): tupla con las matrices Q (ortogonal, m x m) y R (triangular superior, m x n)
            tal que A = Q * R
    """
    m, n = A.shape

    # Obtener todas las matrices de Householder
    matrices_H = obtener_householder(A)

    # Calcular R = H_k ... H_2 H_1 A
    R = A.copy().astype(float)
    for H in matrices_H:
        R = np.dot(H, R)

    # Calcular Q = H_1^T H_2^T ... H_k^T
    # Como las matrices de Householder son simétricas (H = H^T),
    # Q = H_1 H_2 ... H_k
    Q = np.eye(m)
    for H in matrices_H:
        Q = np.dot(Q, H.T)

    return Q, R

def QR_con_GS(A, tol=1e-12,retorna_nops=False):
    nops = 0
    Q = np.zeros(A.shape)
    R = np.zeros(A.shape)

    R[0,0] = norma(A[:,0],2)
    Q[:,0] = A[:,0] / R[0,0]

    for j in range(1,A.shape[0]):
      Q[:,j] = A[:,j]
      for k in range(0, j):
        R[k,j] = np.dot(Q[:,k],Q[:,j])
        Q[:,j] = Q[:,j] - R[k,j]*Q[:,k]
        nops = nops + 4*A.shape[0]
      R[j,j] = norma(Q[:,j],2)
      Q[:,j] = Q[:,j]/R[j,j]
      nops = nops + A.shape[0]

    if(retorna_nops):
      return Q,R,nops
    else:
      return Q,R

# FROM HERE NEW FUNCTIONS --->>>>

def metpot2k(A, tol=1e-15, max_iter=1000):
    """
    Calcula el autovalor dominante (de mayor magnitud) y su autovector
    correspondiente usando el método de la potencia cuadrado (iterando con A^2).

    Argumentos:
    A (np.array): La matriz de entrada (n x n).
    tol (float): Tolerancia para la convergencia.
    max_iter (int/float): Número máximo de iteraciones.

    Devuelve:
    (v, l, k):
      v: El autovector dominante (vector columna n x 1).
      l: El autovalor dominante (escalar).
      k: El número de iteraciones realizadas.
    """
    n = A.shape[0]
    if n == 0:
        return np.array([]).reshape(0,1), 0.0, 0
    if n == 1:
        return np.array([[1.0]]), A[0,0], 0 # Eigenvector for 1x1 is [[1]], eigenvalue is A[0,0]

    v = np.random.rand(n, 1)
    v = v / norma(v,2)

    l_prev = 0.0

    max_iter = int(max_iter)

    for k in range(max_iter):
        w = matMul(A,(matMul(A,v)))
        norma_w = norma(w,2)
        if norma_w < tol:
            return v, 0.0, k

        v_nuevo = w / norma_w
        l_nuevo = matMul(transpuesta(v_nuevo),matMul(A,v_nuevo))[0, 0]

        if np.abs(l_nuevo - l_prev) < tol:
            return v_nuevo, l_nuevo, k

        v = v_nuevo
        l_prev = l_nuevo

    print(f"El método no convergió después de {max_iter} iteraciones.")
    return v, l_nuevo, max_iter


def aplica_H_derecha(A, u_vec, u_norma_sq):
    """
    Calcula A_new = A @ H de forma eficiente en O(n^2).
    H = I - 2*u*u.T / u_norma_sq
    A_new = A @ (I - 2*u*u.T / u_norma_sq)
    A_new = A - (A @ u) @ (2 * u.T / u_norma_sq)
    """
    if u_norma_sq < 1e-20:
        return A

    # (m, n) @ (n, 1) -> (m, 1)
    Au = matMul(A, u_vec)
    # (1, n)
    ut = transpuesta(u_vec)
    # scalar
    const = 2.0 / u_norma_sq

    # (m, 1) @ (1, n) -> (m, n)
    termino = matMul(Au, ut) * const
    return A - termino


def aplica_H_izquierda(A, u_vec, u_norma_sq):
    """
    Calcula A_new = H @ A de forma eficiente en O(n^2).
    H = I - 2*u*u.T / u_norma_sq
    A_new = (I - 2*u*u.T / u_norma_sq) @ A
    A_new = A - (2 * u / u_norma_sq) @ (u.T @ A)
    """
    if u_norma_sq < 1e-20:
        return A

    # (1, n) @ (n, m) -> (1, m)
    u_t_A = matMul(transpuesta(u_vec), A)
    # scalar
    const = 2.0 / u_norma_sq

    # (n, 1) @ (1, m) -> (n, m)
    termino = matMul(u_vec, u_t_A) * const
    return A - termino


def diagRH(A_original, tol=1e-15, K=1000):
    """
    Diagonaliza A (simétrica) usando deflación de Householder
    de forma iterativa y eficiente (O(n^3)).
    """
    n = A_original.shape[0]

    # Manejar casos borde
    if n == 0:
        return np.array([]).reshape(0, 0), np.array([]).reshape(0, 0)
    if n == 1:
        return np.eye(1), np.copy(A_original)

    D = np.zeros((n, n))
    S_final = np.eye(n)
    B = np.copy(A_original)  # B es la matriz de trabajo que será deflacionada

    for i in range(n):  # Loop n veces
        print(f"Iteracion {i}/{n}")
        iter_start_time = time.perf_counter()

        # 1. Definir el subproblema actual B[i:, i:]
        A_sub = B[i:, i:]
        n_sub = A_sub.shape[0]

        # 2. Encontrar autovalor/autovector dominante del subproblema
        # (Usamos tu metpot2k que es k*O(n_sub^2), lo cual es correcto)
        print(f"Calculando metpot {i}/{n}...")
        metpot_start_time = time.perf_counter()
        (autovector_sub, autovalor, k) = metpot2k(A_sub, tol, K)
        metpot_end_time = time.perf_counter()
        metpot_time = metpot_end_time - metpot_start_time
        print(f"metpot {i}/{n} tardo {metpot_time:.4f} segundos.")

        D[i, i] = autovalor

        if n_sub == 1:
            break  # Es el último elemento, no hay más que deflacionar

        # 3. Construir el vector u para la reflexión de Householder
        e_0 = np.zeros((n_sub, 1))
        e_0[0] = 1.0

        if autovector_sub.shape[1] != 1:
            autovector_sub = autovector_sub.reshape(-1, 1)

        # Fórmula numéricamente estable para u
        print("Normalizando U...")
        norma_v = norma(autovector_sub, 2)
        sign_v0 = 1.0 if autovector_sub[0, 0] >= 0 else -1.0
        u_sub = autovector_sub + sign_v0 * norma_v * e_0
        u_norma_sq = norma(u_sub, 2) ** 2
        print("U normalizado.")

        if u_norma_sq < tol:
            # El autovector ya es e_0, no se necesita reflexión
            continue

        # 4. "Embed" u_sub en un vector de tamaño completo n
        u_full = np.zeros((n, 1))
        u_full[i:] = u_sub

        print("Aplicando transformación")
        trans_start = time.perf_counter()
        # 5. Acumular S_final = S_final @ H_full (Operación O(n^2))
        S_final = aplica_H_derecha(S_final, u_full, u_norma_sq)

        # 6. Deflacionar B = H_full @ B @ H_full (Operación O(n^2))
        # H es simétrica (H = H.T)
        B = aplica_H_izquierda(B, u_full, u_norma_sq)
        B = aplica_H_derecha(B, u_full, u_norma_sq)
        trans_end = time.perf_counter()
        trans_time = trans_end - trans_start
        print(f"Transformación tardó {trans_time:.4f} segundos.")

        iter_end_time = time.perf_counter()
    return (S_final, D)

# TO HERE NEW FUNCTIONS <<<------


#def metpot2k(A, tol=1e-15, max_iter=1000):
#    n = A.shape[0]
#    v = np.random.rand(n, 1)
#    v = v / norma(v, 2)
#    l_prev = 0.0
#    max_iter = int(max_iter)
#    A_cuadrado = matMul(A, A) 
#
#    for k in range(max_iter):
#        w = matMul(A_cuadrado, v) 
#
#        norma_w = norma(w, 2)
#        if norma_w < tol:
#            return v, 0.0, k
#
#        v_nuevo = w / norma_w
#        
#        Av_nuevo = matMul(A, v_nuevo)
#        l_nuevo = matMul(transpuesta(v_nuevo), Av_nuevo)[0, 0]
#
#        if np.abs(l_nuevo - l_prev) < tol:
#            return v_nuevo, l_nuevo, k
#
#        v = v_nuevo
#        l_prev = l_nuevo
#
#    print(f"El método no convergió después de {max_iter} iteraciones.")
#    return v, l_nuevo, max_iter
#
#def metpot2k_old(A, tol=1e-15, max_iter=1000):
#    """
#    Calcula el autovalor dominante (de mayor magnitud) y su autovector
#    correspondiente usando el método de la potencia cuadrado (iterando con A^2).
#
#    Argumentos:
#    A (np.array): La matriz de entrada (n x n).
#    tol (float): Tolerancia para la convergencia.
#    max_iter (int/float): Número máximo de iteraciones.
#
#    Devuelve:
#    (v, l, k):
#      v: El autovector dominante (vector columna n x 1).
#      l: El autovalor dominante (escalar).
#      k: El número de iteraciones realizadas.
#    """
#    n = A.shape[0]
#    v = np.random.rand(n, 1)
#    v = v / norma(v,2)
#
#    l_prev = 0.0
#
#    max_iter = int(max_iter)
#
#    for k in range(max_iter):
#        w = matMul(A,(matMul(A,v)))
#        norma_w = norma(w,2)
#        if norma_w < tol:
#            return v, 0.0, k
#
#        v_nuevo = w / norma_w
#        l_nuevo = matMul(transpuesta(v_nuevo),matMul(A,v_nuevo))[0, 0]
#
#        if np.abs(l_nuevo - l_prev) < tol:
#            return v_nuevo, l_nuevo, k
#
#        v = v_nuevo
#        l_prev = l_nuevo
#
#    print(f"El método no convergió después de {max_iter} iteraciones.")
#    return v, l_nuevo, max_iter
#
#def diagRH(A, tol = 1e-15, K = 1000):
#
#    n = A.shape[0]
#    (autovector,autovalor,eps) = metpot2k(A,tol,K)
#    I = np.eye(A.shape[0])
#    e_i = np.zeros_like(autovector)
#    e_i[0] = 1
#
#    u = (e_i - autovector).reshape(-1,1)
#    u_t = u.T
#    u_norma = norma(u,2)
#    H_v = I - 2*((matMul(u,u_t))/(u_norma**2))
#
#    if n == 2:
#        S = H_v
#        D = matMul(H_v,matMul(A,transpuesta(H_v)))
#
#    else:
#
#        B = matMul(H_v,matMul(A,transpuesta(H_v)))
#        A_nuevo = B[1:,1:]
#
#        (S_nuevo, D_nuevo) = diagRH(A_nuevo,tol,K)
#
#        D = np.zeros(B.shape)
#        D[0][0] = autovalor
#        D[1:,1:] = D_nuevo
#
#        S_extra = np.zeros(B.shape)
#        S_extra[0][0] = 1
#        S_extra[1:,1:] = S_nuevo
#
#        S = matMul(H_v,S_extra)
#
#
#    return (S,D)

def transiciones_al_azar_continuas(n):
    """
    n la cantidad de filas (columnas) de la matriz de transición.
    Retorna matriz T de n x n normalizada por columnas, y con entradas al azar en el intervalo [0,1]
    """
    T = np.random.rand(n,n)
    for i in range(n):
      T[:,i] = T[:,i]/norma(T[:,i],1)
    return T

def transiciones_al_azar_uniformes(n,thres):
    """
    n la cantidad de filas (columnas) de la matriz de transición.
    thres probabilidad de que una entrada sea distinta de cero.
    Retorna matriz T de n x n normalizada por columnas.
    El elemento i,j es distinto de cero si el número generado al azar para i,j es menor o igual a thres.
    Todos los elementos de la columna $j$ son iguales
    (a 1 sobre el número de elementos distintos de cero en la columna).
    """
    T = (np.random.rand(n,n) < 0.3).astype(float)
    for i in range(n):
      norm=norma(T[:,i],1)
      if(norm != 0):
          T[:,i] = T[:,i]/norm
      else:
          T[np.random.randint(0,n),i] = 1.
    return T

def nucleo(A,tol=1e-15):
    """
    A una matriz de m x n
    tol la tolerancia para asumir que un vector esta en el nucleo.
    Calcula el nucleo de la matriz A diagonalizando la matriz traspuesta(A) * A (* la multiplicacion matricial), usando el medodo diagRH. El nucleo corresponde a los autovectores de autovalor con modulo <= tol.
    Retorna los autovectores en cuestion, como una matriz de n x k, con k el numero de autovectores en el nucleo.
    """
    diag =  diagRH(matMul(transpuesta(A),A),tol,1000)
    mascara_cero = np.isclose(np.diag(diag[1]), 0, atol=tol)
    return (diag[0])[:, mascara_cero]


def crea_rala(listado,m_filas,n_columnas,tol=1e-15):
    """
    Recibe una lista listado, con tres elementos: lista con indices i, lista con indices j, y lista con valores A_ij de la matriz A. Tambien las dimensiones de la matriz a traves de m_filas y n_columnas. Los elementos menores a tol se descartan.
    Idealmente, el listado debe incluir unicamente posiciones correspondientes a valores distintos de cero. Retorna una lista con:
    - Diccionario {(i,j):A_ij} que representa los elementos no nulos de la matriz A. Los elementos con modulo menor a tol deben descartarse por default.
    - Tupla (m_filas,n_columnas) que permita conocer las dimensiones de la matriz.
    """
    matriz = {}
    if(len(listado) != 0):
      for i,j,aij in zip(listado[0],listado[1],listado[2]):
        if(abs(aij) >= tol):
            matriz[(i,j)] = aij
    return matriz, (m_filas, n_columnas)

def multiplica_rala_vector(A,v):
    """
    Recibe una matriz rala creada con crea_rala y un vector v.
    Retorna un vector w resultado de multiplicar A con v
    """
    b = np.zeros_like(v)

    for elem in A[0].keys():
         b[elem[0]] = b[elem[0]] + A[0][elem]*v[elem[1]]
    return b

def es_markov(T,tol=1e-6):
    """
    T una matriz cuadrada.
    tol la tolerancia para asumir que una suma es igual a 1.
    Retorna True si T es una matriz de transición de Markov (entradas no negativas y columnas que suman 1 dentro de la tolerancia), False en caso contrario.
    """
    n = T.shape[0]
    for i in range(n):
        for j in range(n):
            if T[i,j]<0:
                return False
    for j in range(n):
        suma_columna = sum(T[:,j])
        if np.abs(suma_columna - 1) > tol:
            return False
    return True

def es_markov_uniforme(T,thres=1e-6):
    """
    T una matriz cuadrada.
    thres la tolerancia para asumir que una entrada es igual a cero.
    Retorna True si T es una matriz de transición de Markov uniforme (entradas iguales a cero o iguales entre si en cada columna, y columnas que suman 1 dentro de la tolerancia), False en caso contrario.
    """
    if not es_markov(T,thres):
        return False
    # cada columna debe tener entradas iguales entre si o iguales a cero
    m = T.shape[1]
    for j in range(m):
        non_zero = T[:,j][T[:,j] > thres]
        # all close
        close = all(np.abs(non_zero - non_zero[0]) < thres)
        if not close:
            return False
    return True

def esNucleo(A,S,tol=1e-5):
    """
    A una matriz m x n
    S una matriz n x k
    tol la tolerancia para asumir que un vector esta en el nucleo.
    Retorna True si las columnas de S estan en el nucleo de A (es decir, A*S = 0. Esto no chequea si es todo el nucleo
    """
    for col in S.T:
        res = A @ col
        if not np.allclose(res,np.zeros(A.shape[0]), atol=tol):
            return False
    return True


def cholesky(A):
    """
    Realiza la descomposición de Cholesky de una matriz simétrica y definida positiva A.
    Retorna una matriz L tal que A = L * L^T
    """
    n = A.shape[0]
    L = np.zeros_like(A)

    for i in range(n):
        for j in range(i + 1):
            if i == j:
                L[i, j] = np.sqrt(A[i, i] - np.sum(L[i, :j] ** 2))
            else:
                L[i, j] = (A[i, j] - np.sum(L[i, :j] * L[j, :j])) / L[j, j]

    return L, transpuesta(L)

def svd_reducida(A, k="max", tol=1e-15):
    """
    A la matriz de interes (de m x n)
    k el numero de valores singulares (y vectores) a retener.
    tol la tolerancia para considerar un valor singular igual a cero
    Retorna hatU (matriz de m x k), hatSig (matriz diagonal de k x k) y hatV (matriz de n x k)
    """
    m, n = A.shape
    print("Dimension de A:,", A.shape)
    print(f"{m} filas y {n} columnas.")
    
    if m < n:
        print("Caso m<n")
        print("Calculando A*AT...")
        mult_mat_start_time = time.perf_counter()
        B = matMul(A, transpuesta(A))
        mult_mat_end_time = time.perf_counter()
        mult_mat_time = mult_mat_end_time - mult_mat_start_time
        print(f"A*AT calculada en {mult_mat_time:.4f} segundos")
        print("Calculando DiagRH de A*AT para obtener diagonalización")
        diagonalizacion = diagRH(B, tol,1000)
        print("Diagonalizacion calculada")
        U = diagonalizacion[0]
        D = diagonalizacion[1]

        autovalores_orig = np.diag(D)
        indices_ordenados = np.argsort(autovalores_orig)[::-1]
        autovalores_ordenados = autovalores_orig[indices_ordenados]
        U_ordenado = U[:, indices_ordenados]

        autovalores_filtrados = autovalores_ordenados[autovalores_ordenados >= tol]
        valores_singulares = np.sqrt(autovalores_filtrados)
        r = len(valores_singulares)

        if k == "max":
            k_eff = r
        else:
            k_eff = min(int(k), r)

        hatS = np.diag(valores_singulares[:k_eff])
        hatU = U_ordenado[:, :k_eff]

        hatV = np.zeros((A.shape[1], k_eff))
        B_v = matMul(transpuesta(A), hatU)

        for i in range(k_eff):
            sigma_i = hatS[i, i]
            if sigma_i >= tol:
                hatV[:, i] = B_v[:, i] / sigma_i

    else: # (m >= n)
        B = matMul(transpuesta(A), A)
        diagonalizacion = diagRH(B, tol,1000)
        V = diagonalizacion[0]
        D = diagonalizacion[1]

        autovalores_orig = np.diag(D)
        indices_ordenados = np.argsort(autovalores_orig)[::-1]
        autovalores_ordenados = autovalores_orig[indices_ordenados]
        V_ordenado = V[:, indices_ordenados]

        autovalores_filtrados = autovalores_ordenados[autovalores_ordenados >= tol]
        valores_singulares = np.sqrt(autovalores_filtrados)
        r = len(valores_singulares)

        if k == "max":
            k_eff = r
        else:
            k_eff = min(int(k), r)

        hatS = np.diag(valores_singulares[:k_eff])
        hatV = V_ordenado[:, :k_eff]

        hatU = np.zeros((A.shape[0], k_eff))
        B_u = matMul(A, hatV)

        for i in range(k_eff):
            sigma_i = hatS[i, i]
            if sigma_i >= tol:
                hatU[:, i] = B_u[:, i] / sigma_i

    return hatU, hatS, hatV

try:
    # 1. Determine the correct file extension based on the OS
    if sys.platform.startswith('darwin'):
        # macOS uses .dylib or .so (but .dylib is more common for system)
        lib_ext = ".dylib"
    elif sys.platform.startswith('linux'):
        # Linux uses .so
        lib_ext = ".so"
    else:
        # Fallback for other systems (like Windows, where it would be .dll)
        # We'll stick to the provided extensions for now
        raise OSError(f"Unsupported OS for C extension: {sys.platform}")

    # 2. Construct the library path
    lib_name = "aux" + lib_ext
    
    # Use os.path.join for cross-platform path construction
    # Note: If your script is in a different location than 'aux.so', you'll need
    # to provide a full or relative path here. We assume they are together.
    lib_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), lib_name)

    # 3. Load the library
    aux = ctypes.CDLL(lib_path)
    print(f"Loaded {lib_name} ({sys.platform})")

    # 4. Find the C function
    # The author's original logic for checking the underscore prefix is kept, 
    # as macOS C compilers sometimes mangle function names with a leading underscore.
    try:
        # Try with underscore prefix (macOS convention)
        calcularAX_func = aux._calcularAX
    except AttributeError:
        # Try without underscore (Linux/standard convention)
        calcularAX_func = aux.calcularAX
    
    # 5. Configure function types (remains the same as this is C-specific)
    calcularAX_func.argtypes = [
      ctypes.POINTER(ctypes.c_float), ctypes.POINTER(ctypes.c_float),
      ctypes.POINTER(ctypes.c_float), ctypes.c_int, ctypes.c_int
    ]

    # 6. Define the Python wrapper function
    def _calcularAxFast(A,x):
      # Ensure inputs are float32 and contiguous for C compatibility
      A_f32 = np.ascontiguousarray(A, dtype=np.float32)
      x_f32 = np.ascontiguousarray(x, dtype=np.float32)
      
      n_rows = A_f32.shape[0]
      n_cols = A_f32.shape[1]
      
      # Convert numpy data buffers to C pointers
      A_ctypes = A_f32.ctypes.data_as(ctypes.POINTER(ctypes.c_float))
      x_ctypes = x_f32.ctypes.data_as(ctypes.POINTER(ctypes.c_float))
      
      # Prepare the result buffer
      res = np.zeros(n_rows, dtype=np.float32)
      res_ctypes = res.ctypes.data_as(ctypes.POINTER(ctypes.c_float))

      # Call the C function
      calcularAX_func(A_ctypes, x_ctypes, res_ctypes, n_rows, n_cols)
      return res
    
    # Set the public function to the fast C version
    calcularAxFast = _calcularAxFast
    print("USING FAST CODE")

# 7. Error Handling: Fallback to slow code if C loading fails
except Exception as e:
  print(f"Error loading or configuring C extension: {e}")
  print("USING SLOW CODE")
  # calcularAxFast is already set to calcularAx from the start
